{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200 227 254]\n",
      "Frame number 1 took 0.34231 seconds\n",
      "Frame number 2 took 0.09232 seconds\n",
      "Frame number 3 took 0.09160 seconds\n",
      "Frame number 4 took 0.08507 seconds\n",
      "Frame number 5 took 0.08805 seconds\n",
      "Frame number 6 took 0.08978 seconds\n",
      "Frame number 7 took 0.08926 seconds\n",
      "Frame number 8 took 0.08577 seconds\n",
      "Frame number 9 took 0.08214 seconds\n",
      "Frame number 10 took 0.08537 seconds\n",
      "Frame number 11 took 0.08341 seconds\n",
      "Frame number 12 took 0.08524 seconds\n",
      "Frame number 13 took 0.08420 seconds\n",
      "Frame number 14 took 0.08533 seconds\n",
      "Frame number 15 took 0.08427 seconds\n",
      "Frame number 16 took 0.08172 seconds\n",
      "Frame number 17 took 0.08070 seconds\n",
      "Frame number 18 took 0.08502 seconds\n",
      "Frame number 19 took 0.08590 seconds\n",
      "Frame number 20 took 0.08502 seconds\n",
      "Frame number 21 took 0.08317 seconds\n",
      "Frame number 22 took 0.08546 seconds\n",
      "Frame number 23 took 0.08469 seconds\n",
      "Frame number 24 took 0.08480 seconds\n",
      "Frame number 25 took 0.08258 seconds\n",
      "Frame number 26 took 0.08605 seconds\n",
      "Frame number 27 took 0.08666 seconds\n",
      "Frame number 28 took 0.09231 seconds\n",
      "Frame number 29 took 0.08622 seconds\n",
      "Frame number 30 took 0.08599 seconds\n",
      "Frame number 31 took 0.08443 seconds\n",
      "Frame number 32 took 0.08208 seconds\n",
      "Frame number 33 took 0.08398 seconds\n",
      "Frame number 34 took 0.08648 seconds\n",
      "Frame number 35 took 0.08585 seconds\n",
      "Frame number 36 took 0.08724 seconds\n",
      "Frame number 37 took 0.08242 seconds\n",
      "Frame number 38 took 0.08836 seconds\n",
      "Frame number 39 took 0.08856 seconds\n",
      "Frame number 40 took 0.08280 seconds\n",
      "Frame number 41 took 0.08774 seconds\n",
      "Frame number 42 took 0.08374 seconds\n",
      "Frame number 43 took 0.08416 seconds\n",
      "Frame number 44 took 0.08907 seconds\n",
      "Frame number 45 took 0.08751 seconds\n",
      "Frame number 46 took 0.08380 seconds\n",
      "Frame number 47 took 0.08542 seconds\n",
      "Frame number 48 took 0.09351 seconds\n",
      "Frame number 49 took 0.08452 seconds\n",
      "Frame number 50 took 0.08568 seconds\n",
      "Frame number 51 took 0.08397 seconds\n",
      "Frame number 52 took 0.08798 seconds\n",
      "Frame number 53 took 0.09180 seconds\n",
      "Frame number 54 took 0.08541 seconds\n",
      "Frame number 55 took 0.08660 seconds\n",
      "Frame number 56 took 0.08468 seconds\n",
      "Frame number 57 took 0.08333 seconds\n",
      "Frame number 58 took 0.09129 seconds\n",
      "Frame number 59 took 0.08861 seconds\n",
      "Frame number 60 took 0.09089 seconds\n",
      "Frame number 61 took 0.08339 seconds\n",
      "Frame number 62 took 0.09373 seconds\n",
      "Frame number 63 took 0.08924 seconds\n",
      "Frame number 64 took 0.08585 seconds\n",
      "Frame number 65 took 0.08249 seconds\n",
      "Frame number 66 took 0.08522 seconds\n",
      "Frame number 67 took 0.09202 seconds\n",
      "Frame number 68 took 0.08981 seconds\n",
      "Frame number 69 took 0.08383 seconds\n",
      "Frame number 70 took 0.08341 seconds\n",
      "Frame number 71 took 0.08909 seconds\n",
      "Frame number 72 took 0.09172 seconds\n",
      "Frame number 73 took 0.08520 seconds\n",
      "Frame number 74 took 0.09001 seconds\n",
      "Frame number 75 took 0.08565 seconds\n",
      "Frame number 76 took 0.08409 seconds\n",
      "Frame number 77 took 0.08156 seconds\n",
      "Frame number 78 took 0.08540 seconds\n",
      "Frame number 79 took 0.08008 seconds\n",
      "Frame number 80 took 0.08567 seconds\n",
      "Frame number 81 took 0.08730 seconds\n",
      "Frame number 82 took 0.08422 seconds\n",
      "Frame number 83 took 0.08450 seconds\n",
      "Frame number 84 took 0.08972 seconds\n",
      "Frame number 85 took 0.08702 seconds\n",
      "Frame number 86 took 0.08881 seconds\n",
      "Frame number 87 took 0.08351 seconds\n",
      "Frame number 88 took 0.08439 seconds\n",
      "Frame number 89 took 0.08307 seconds\n",
      "Frame number 90 took 0.08545 seconds\n",
      "Frame number 91 took 0.08595 seconds\n",
      "Frame number 92 took 0.08536 seconds\n",
      "Frame number 93 took 0.08525 seconds\n",
      "Frame number 94 took 0.09039 seconds\n",
      "Frame number 95 took 0.11573 seconds\n",
      "Frame number 96 took 0.08686 seconds\n",
      "Frame number 97 took 0.08661 seconds\n",
      "Frame number 98 took 0.09275 seconds\n",
      "Frame number 99 took 0.08468 seconds\n",
      "Frame number 100 took 0.09046 seconds\n",
      "Frame number 101 took 0.08499 seconds\n",
      "Frame number 102 took 0.08461 seconds\n",
      "Frame number 103 took 0.10271 seconds\n",
      "Frame number 104 took 0.08530 seconds\n",
      "Frame number 105 took 0.09844 seconds\n",
      "Frame number 106 took 0.08395 seconds\n",
      "Frame number 107 took 0.08751 seconds\n",
      "Frame number 108 took 0.08896 seconds\n",
      "Frame number 109 took 0.08625 seconds\n",
      "Frame number 110 took 0.08706 seconds\n",
      "Frame number 111 took 0.08569 seconds\n",
      "Frame number 112 took 0.08623 seconds\n",
      "Frame number 113 took 0.08882 seconds\n",
      "Frame number 114 took 0.09507 seconds\n",
      "Frame number 115 took 0.08421 seconds\n",
      "Frame number 116 took 0.08753 seconds\n",
      "Frame number 117 took 0.09099 seconds\n",
      "Frame number 118 took 0.08755 seconds\n",
      "Frame number 119 took 0.08880 seconds\n",
      "Frame number 120 took 0.08994 seconds\n",
      "Frame number 121 took 0.09267 seconds\n",
      "Frame number 122 took 0.08383 seconds\n",
      "Frame number 123 took 0.09051 seconds\n",
      "Frame number 124 took 0.08487 seconds\n",
      "Frame number 125 took 0.08454 seconds\n",
      "Frame number 126 took 0.08364 seconds\n",
      "Frame number 127 took 0.08360 seconds\n",
      "Frame number 128 took 0.08453 seconds\n",
      "Frame number 129 took 0.08632 seconds\n",
      "Frame number 130 took 0.09686 seconds\n",
      "Frame number 131 took 0.08400 seconds\n",
      "Frame number 132 took 0.08783 seconds\n",
      "Frame number 133 took 0.09174 seconds\n",
      "Frame number 134 took 0.08828 seconds\n",
      "Frame number 135 took 0.08427 seconds\n",
      "Frame number 136 took 0.09163 seconds\n",
      "Frame number 137 took 0.08755 seconds\n",
      "Frame number 138 took 0.09401 seconds\n",
      "Frame number 139 took 0.08513 seconds\n",
      "Frame number 140 took 0.08392 seconds\n",
      "Frame number 141 took 0.08365 seconds\n",
      "Frame number 142 took 0.08621 seconds\n",
      "Frame number 143 took 0.08393 seconds\n",
      "Frame number 144 took 0.08907 seconds\n",
      "Frame number 145 took 0.08564 seconds\n",
      "Frame number 146 took 0.08779 seconds\n",
      "Frame number 147 took 0.08267 seconds\n",
      "Frame number 148 took 0.09058 seconds\n",
      "Frame number 149 took 0.08879 seconds\n",
      "Frame number 150 took 0.08500 seconds\n",
      "Frame number 151 took 0.08715 seconds\n",
      "Frame number 152 took 0.08738 seconds\n",
      "Frame number 153 took 0.08926 seconds\n",
      "Frame number 154 took 0.09046 seconds\n",
      "Frame number 155 took 0.08673 seconds\n",
      "Frame number 156 took 0.09155 seconds\n",
      "Frame number 157 took 0.09031 seconds\n",
      "Frame number 158 took 0.08823 seconds\n",
      "Frame number 159 took 0.08850 seconds\n",
      "Frame number 160 took 0.08899 seconds\n",
      "Frame number 161 took 0.08804 seconds\n",
      "Frame number 162 took 0.08548 seconds\n",
      "Frame number 163 took 0.09280 seconds\n",
      "Frame number 164 took 0.09184 seconds\n",
      "Frame number 165 took 0.08469 seconds\n",
      "Frame number 166 took 0.09364 seconds\n",
      "Frame number 167 took 0.10060 seconds\n",
      "Frame number 168 took 0.09469 seconds\n",
      "Frame number 169 took 0.09600 seconds\n",
      "Frame number 170 took 0.10297 seconds\n",
      "Frame number 171 took 0.10068 seconds\n",
      "Frame number 172 took 0.09810 seconds\n",
      "Frame number 173 took 0.09003 seconds\n",
      "Frame number 174 took 0.08668 seconds\n",
      "Frame number 175 took 0.08385 seconds\n",
      "Frame number 176 took 0.09108 seconds\n",
      "Frame number 177 took 0.08663 seconds\n",
      "Frame number 178 took 0.08400 seconds\n",
      "Frame number 179 took 0.09035 seconds\n",
      "Frame number 180 took 0.08973 seconds\n",
      "Frame number 181 took 0.08780 seconds\n",
      "Frame number 182 took 0.08857 seconds\n",
      "Frame number 183 took 0.08999 seconds\n",
      "Frame number 184 took 0.08433 seconds\n",
      "Frame number 185 took 0.08545 seconds\n",
      "Frame number 186 took 0.09182 seconds\n",
      "Frame number 187 took 0.08969 seconds\n",
      "Frame number 188 took 0.08870 seconds\n",
      "Frame number 189 took 0.08458 seconds\n",
      "Frame number 190 took 0.09141 seconds\n",
      "Frame number 191 took 0.08877 seconds\n",
      "Frame number 192 took 0.08814 seconds\n",
      "Frame number 193 took 0.08529 seconds\n",
      "Frame number 194 took 0.08636 seconds\n",
      "Frame number 195 took 0.08449 seconds\n",
      "Frame number 196 took 0.09660 seconds\n",
      "Frame number 197 took 0.08590 seconds\n",
      "Frame number 198 took 0.08822 seconds\n",
      "Frame number 199 took 0.08413 seconds\n",
      "Frame number 200 took 0.09031 seconds\n",
      "Frame number 201 took 0.08780 seconds\n",
      "Frame number 202 took 0.08894 seconds\n",
      "Frame number 203 took 0.09030 seconds\n",
      "Frame number 204 took 0.08947 seconds\n",
      "Frame number 205 took 0.08200 seconds\n",
      "Frame number 206 took 0.09370 seconds\n",
      "Frame number 207 took 0.09033 seconds\n",
      "Frame number 208 took 0.09076 seconds\n",
      "Frame number 209 took 0.09081 seconds\n",
      "Frame number 210 took 0.09089 seconds\n",
      "Frame number 211 took 0.08384 seconds\n",
      "Frame number 212 took 0.08693 seconds\n",
      "Frame number 213 took 0.08550 seconds\n",
      "Frame number 214 took 0.09201 seconds\n",
      "Frame number 215 took 0.08728 seconds\n",
      "Frame number 216 took 0.09039 seconds\n",
      "Frame number 217 took 0.08474 seconds\n",
      "Frame number 218 took 0.08995 seconds\n",
      "Frame number 219 took 0.09377 seconds\n",
      "Frame number 220 took 0.09426 seconds\n",
      "Frame number 221 took 0.08142 seconds\n",
      "Frame number 222 took 0.08618 seconds\n",
      "Frame number 223 took 0.08560 seconds\n",
      "Frame number 224 took 0.09256 seconds\n",
      "Frame number 225 took 0.09459 seconds\n",
      "Frame number 226 took 0.09323 seconds\n",
      "Frame number 227 took 0.09037 seconds\n",
      "Frame number 228 took 0.09305 seconds\n",
      "Frame number 229 took 0.09346 seconds\n",
      "Frame number 230 took 0.10046 seconds\n",
      "Frame number 231 took 0.08895 seconds\n",
      "Frame number 232 took 0.09415 seconds\n",
      "Frame number 233 took 0.08484 seconds\n",
      "Frame number 234 took 0.09061 seconds\n",
      "Frame number 235 took 0.08980 seconds\n",
      "Frame number 236 took 0.08620 seconds\n",
      "Frame number 237 took 0.08578 seconds\n",
      "Frame number 238 took 0.09248 seconds\n",
      "Frame number 239 took 0.08820 seconds\n",
      "Frame number 240 took 0.08774 seconds\n",
      "Frame number 241 took 0.08822 seconds\n",
      "Frame number 242 took 0.09327 seconds\n",
      "Frame number 243 took 0.08609 seconds\n",
      "Frame number 244 took 0.08421 seconds\n",
      "Frame number 245 took 0.08585 seconds\n",
      "Frame number 246 took 0.09124 seconds\n",
      "Frame number 247 took 0.08843 seconds\n",
      "Frame number 248 took 0.08788 seconds\n",
      "Frame number 249 took 0.08600 seconds\n",
      "Frame number 250 took 0.08949 seconds\n",
      "Frame number 251 took 0.08687 seconds\n",
      "Frame number 252 took 0.09043 seconds\n",
      "Frame number 253 took 0.08693 seconds\n",
      "Frame number 254 took 0.08519 seconds\n",
      "Frame number 255 took 0.08678 seconds\n",
      "Frame number 256 took 0.08917 seconds\n",
      "Frame number 257 took 0.08607 seconds\n",
      "Frame number 258 took 0.09235 seconds\n",
      "Frame number 259 took 0.08598 seconds\n",
      "Frame number 260 took 0.08353 seconds\n",
      "Frame number 261 took 0.08929 seconds\n",
      "Frame number 262 took 0.08802 seconds\n",
      "Frame number 263 took 0.08921 seconds\n",
      "Frame number 264 took 0.08950 seconds\n",
      "Frame number 265 took 0.08397 seconds\n",
      "Frame number 266 took 0.08828 seconds\n",
      "Frame number 267 took 0.08874 seconds\n",
      "Frame number 268 took 0.08591 seconds\n",
      "Frame number 269 took 0.08803 seconds\n",
      "Frame number 270 took 0.08680 seconds\n",
      "Frame number 271 took 0.08178 seconds\n",
      "Frame number 272 took 0.08517 seconds\n",
      "Frame number 273 took 0.08891 seconds\n",
      "Frame number 274 took 0.09355 seconds\n",
      "Frame number 275 took 0.08473 seconds\n",
      "Frame number 276 took 0.08653 seconds\n",
      "Frame number 277 took 0.08359 seconds\n",
      "Frame number 278 took 0.08529 seconds\n",
      "Frame number 279 took 0.08517 seconds\n",
      "Frame number 280 took 0.08494 seconds\n",
      "Frame number 281 took 0.08535 seconds\n",
      "Frame number 282 took 0.08289 seconds\n",
      "Frame number 283 took 0.08067 seconds\n",
      "Frame number 284 took 0.08568 seconds\n",
      "Frame number 285 took 0.08347 seconds\n",
      "Frame number 286 took 0.08749 seconds\n",
      "Frame number 287 took 0.08601 seconds\n",
      "Frame number 288 took 0.08243 seconds\n",
      "Frame number 289 took 0.08246 seconds\n",
      "Frame number 290 took 0.08612 seconds\n",
      "Frame number 291 took 0.08411 seconds\n",
      "Frame number 292 took 0.08395 seconds\n",
      "Frame number 293 took 0.08407 seconds\n",
      "Frame number 294 took 0.08311 seconds\n",
      "Frame number 295 took 0.08891 seconds\n",
      "Frame number 296 took 0.08561 seconds\n",
      "Frame number 297 took 0.08520 seconds\n",
      "Frame number 298 took 0.08272 seconds\n",
      "Frame number 299 took 0.08413 seconds\n",
      "Frame number 300 took 0.08701 seconds\n",
      "Frame number 301 took 0.08359 seconds\n",
      "Frame number 302 took 0.08517 seconds\n",
      "Frame number 303 took 0.08466 seconds\n",
      "Frame number 304 took 0.09117 seconds\n",
      "Frame number 305 took 0.09246 seconds\n",
      "Frame number 306 took 0.08834 seconds\n",
      "Frame number 307 took 0.08554 seconds\n",
      "Frame number 308 took 0.08616 seconds\n",
      "Frame number 309 took 0.08372 seconds\n",
      "Frame number 310 took 0.09251 seconds\n",
      "Frame number 311 took 0.08661 seconds\n",
      "Frame number 312 took 0.08589 seconds\n",
      "Frame number 313 took 0.08547 seconds\n",
      "Frame number 314 took 0.08331 seconds\n",
      "Frame number 315 took 0.08962 seconds\n",
      "Frame number 316 took 0.08906 seconds\n",
      "Frame number 317 took 0.08581 seconds\n",
      "Frame number 318 took 0.08549 seconds\n",
      "Frame number 319 took 0.08614 seconds\n",
      "Frame number 320 took 0.11304 seconds\n",
      "Frame number 321 took 0.09238 seconds\n",
      "Frame number 322 took 0.08695 seconds\n",
      "Frame number 323 took 0.08805 seconds\n",
      "Frame number 324 took 0.08714 seconds\n",
      "Frame number 325 took 0.08512 seconds\n",
      "Frame number 326 took 0.08727 seconds\n",
      "Frame number 327 took 0.08763 seconds\n",
      "Frame number 328 took 0.08773 seconds\n",
      "Frame number 329 took 0.08217 seconds\n",
      "Frame number 330 took 0.08784 seconds\n",
      "Frame number 331 took 0.08640 seconds\n",
      "Frame number 332 took 0.08980 seconds\n",
      "Frame number 333 took 0.08402 seconds\n",
      "Frame number 334 took 0.08852 seconds\n",
      "Frame number 335 took 0.08434 seconds\n",
      "Frame number 336 took 0.08636 seconds\n",
      "Frame number 337 took 0.08664 seconds\n",
      "Frame number 338 took 0.08782 seconds\n",
      "Frame number 339 took 0.08670 seconds\n",
      "Frame number 340 took 0.08492 seconds\n",
      "Frame number 341 took 0.08477 seconds\n",
      "Frame number 342 took 0.08745 seconds\n",
      "Frame number 343 took 0.08565 seconds\n",
      "Frame number 344 took 0.08789 seconds\n",
      "Frame number 345 took 0.08365 seconds\n",
      "Frame number 346 took 0.08668 seconds\n",
      "Frame number 347 took 0.08698 seconds\n",
      "Frame number 348 took 0.08721 seconds\n",
      "Frame number 349 took 0.08549 seconds\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 285\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m prev_results\u001b[38;5;241m.\u001b[39mflatten():\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(label \u001b[38;5;241m==\u001b[39m labels[\u001b[38;5;28mint\u001b[39m(prev_labels[j])]):\n\u001b[0;32m--> 285\u001b[0m         prev_x_min, prev_y_min, prev_box_width, prev_box_height \u001b[38;5;241m=\u001b[39m \u001b[43mprev_boxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    286\u001b[0m         prev_center \u001b[38;5;241m=\u001b[39m (prev_x_min \u001b[38;5;241m+\u001b[39m prev_box_width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, prev_y_min \u001b[38;5;241m+\u001b[39m prev_box_height\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    287\u001b[0m         dists\u001b[38;5;241m.\u001b[39mappend([prev_center[\u001b[38;5;241m0\u001b[39m],prev_center[\u001b[38;5;241m1\u001b[39m],euclid_2D(center,prev_center)])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#Parameters for the first video.\n",
    "pedestrian_y_threshold_1 = 0.7\n",
    "pedestrian_y_threshold_2 = 0.75\n",
    "y_threshold_1 = 0.72\n",
    "y_threshold_2 = 0.84\n",
    "parking_x_threshold = 0.15\n",
    "\"\"\"\n",
    "==================     STEP1   ===================\n",
    "Start of: Reading input video\n",
    "\"\"\"\n",
    "#NOTE:\n",
    "# Defining 'VideoCapture' object and reading video from a file make sure that the path and file name is correct\n",
    "video = cv2.VideoCapture( 'mcgill_drive.mp4')\n",
    "\n",
    "# Preparing variable for writer that we will use to write processed frames\n",
    "writer = None\n",
    "\n",
    "# Preparing variables for spatial dimensions of the frames\n",
    "h, w = None, None\n",
    "\n",
    "\"\"\"\n",
    "End of:\n",
    "Reading input video\n",
    "\"\"\"\n",
    "'''\n",
    "Helper Methods. \n",
    "Euclid_2D calculates the euclidean distance between two pixels in the image (useful for object matching between different frames).\n",
    "is_above_line_2D checks if a pixel (target) is above a line described by two other pixels (line_pt1,line_pt2) in a frame.\n",
    "'''\n",
    "def euclid_2D(pt1,pt2):\n",
    "    return np.sqrt((pt1[0] - pt2[0])**2 + (pt1[1] - pt2[1])**2)\n",
    "\n",
    "def is_above_line_2D(line_pt1, line_pt2, target):\n",
    "    a = (line_pt2[1]-line_pt1[1])/(line_pt2[0]-line_pt1[0])\n",
    "    b = line_pt1[1] - line_pt1[0] * a\n",
    "    return (target[1] > (a * target[0] + b))\n",
    "\n",
    "def draw_label(img, text, pos, bg_color):\n",
    "    font_scale = 0.5\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    (text_width, text_height) = cv2.getTextSize(text, font, fontScale=font_scale, thickness=1)[0]\n",
    "    box_coords = ((pos[0], pos[1]), (pos[0] + text_width + 2, pos[1] - text_height - 2))\n",
    "    cv2.rectangle(img, box_coords[0], box_coords[1], bg_color, cv2.FILLED)\n",
    "    cv2.putText(img, text, (pos[0], pos[1]), font, fontScale=font_scale, color=(0,0,0), thickness=1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "==================     STEP2  ===================\n",
    "Start of: Loading YOLO v3 network\n",
    "\"\"\"\n",
    "\n",
    "# Loading COCO class labels from file and Opening file\n",
    "with open('yolo_data/coco.names') as f:\n",
    "    # Getting labels reading every line\n",
    "    # and putting them into the list\n",
    "    labels = [line.strip() for line in f]\n",
    "\n",
    "\n",
    "# Loading trained YOLO v3 Objects Detector with the help of 'dnn' library from OpenCV\n",
    "network = cv2.dnn.readNetFromDarknet('yolo_data/yolov3.cfg',\n",
    "                                     'yolo_data/yolov3.weights')\n",
    "\n",
    "# Getting list with names of all layers from YOLO v3 network\n",
    "layers_names_all = network.getLayerNames()\n",
    "\n",
    "# Getting only output layers' names that we need from YOLO v3 algorithm\n",
    "# with function that returns indexes of layers with unconnected outputs\n",
    "print(network.getUnconnectedOutLayers())\n",
    "layers_names_output = [layers_names_all[i - 1] for i in network.getUnconnectedOutLayers()]\n",
    "\n",
    "# Setting minimum probability to eliminate weak predictions\n",
    "probability_minimum = 0.7\n",
    "\n",
    "# Setting threshold for filtering weak bounding boxes\n",
    "# with non-maximum suppression\n",
    "threshold = 0.3\n",
    "\n",
    "# Generating colours for representing every detected object\n",
    "# with function randint(low, high=None, size=None, dtype='l')\n",
    "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
    "\n",
    "\"\"\"\n",
    "==================     STEP3  ===================\n",
    "Start of: Reading frames in the loop\n",
    "\"\"\"\n",
    "\n",
    "# Defining variable for counting frames at the end we will show total amount of processed frames\n",
    "f = 0\n",
    "\n",
    "# Defining variable for counting total time At the end we will show time spent for processing all frames\n",
    "t = 0\n",
    "\n",
    "# Defining loop for catching frames\n",
    "total_cars_count = 0\n",
    "parked_cars_count = 0\n",
    "total_pedestrian_count = 0\n",
    "\n",
    "prev_results = []\n",
    "\n",
    "prev_boxes = []\n",
    "\n",
    "prev_labels = []\n",
    "\n",
    "while True:\n",
    "    # Capturing frame-by-frame\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # If the frame was not retrieved e.g.: at the end of the video, then we break the loop\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Getting spatial dimensions of the frame as we do it only once from the very beginning\n",
    "    # all other frames have the same dimension\n",
    "    if w is None or h is None:\n",
    "        # Slicing from tuple only first two elements\n",
    "        h, w = frame.shape[:2]\n",
    "    \n",
    "    \"\"\"\n",
    "    End of: Reading frame in loop\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ==================     STEP4  ===================\n",
    "    Start of: Getting blob from current frame\n",
    "    \"\"\"\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    \"\"\"\n",
    "    End of: Getting blob from current frame\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ==================     STEP4  ===================\n",
    "    Start of: Implementing Forward pass\n",
    "    \"\"\"\n",
    "\n",
    "    # Implementing forward pass with our blob and only through output layers\n",
    "    # Calculating at the same time, needed time for forward pass\n",
    "    network.setInput(blob)  # setting blob as input to the network\n",
    "    output_from_network = network.forward(layers_names_output)\n",
    "\n",
    "\n",
    "    # Increasing counters for frames and total time\n",
    "    f += 1\n",
    "\n",
    "    # Showing spent time for single current frame\n",
    "    print('Processing frame number {0}'.format(f))\n",
    "    \n",
    "    \"\"\"\n",
    "    End of:Implementing Forward pass\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    ==================     STEP5  ===================\n",
    "    Start of: Getting bounding boxes\n",
    "    \"\"\"\n",
    "\n",
    "    # Preparing lists for detected bounding boxes, obtained confidences and class's number\n",
    "    boxes = []\n",
    "\n",
    "    confidences = []\n",
    "\n",
    "    current_labels = []\n",
    "\n",
    "    # Going through all output layers after feed forward pass\n",
    "    for result in output_from_network:\n",
    "        # Going through all detections from current output layer\n",
    "        for detected_objects in result:\n",
    "            # Getting 80 classes' probabilities for current detected object\n",
    "            scores = detected_objects[5:]\n",
    "            # Getting index of the class with the maximum value of probability\n",
    "            class_current = np.argmax(scores)\n",
    "            # Getting value of probability for defined class\n",
    "            confidence_current = scores[class_current]\n",
    "            \n",
    "            # # Every 'detected_objects' numpy array has first 4 numbers with\n",
    "            # # bounding box coordinates and rest 80 with probabilities\n",
    "            #  # for every class\n",
    "\n",
    "            # Eliminating weak predictions with minimum probability\n",
    "            if confidence_current > probability_minimum:\n",
    "                # Scaling bounding box coordinates to the initial frame size\n",
    "                # YOLO data format keeps coordinates for center of bounding box\n",
    "                # and its current width and height\n",
    "                # That is why we can just multiply them elementwise\n",
    "                # to the width and height\n",
    "                # of the original frame and in this way get coordinates for center\n",
    "                # of bounding box, its width and height for original frame\n",
    "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "                # Now, from YOLO data format, we can get top left corner coordinates that are x_min and y_min\n",
    "                x_center, y_center, box_width, box_height = box_current\n",
    "                x_min = int(x_center - (box_width / 2))\n",
    "                y_min = int(y_center - (box_height / 2))\n",
    "\n",
    "                # Adding results into prepared lists\n",
    "                boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "                confidences.append(float(confidence_current))\n",
    "                current_labels.append(class_current)\n",
    "            \t\n",
    "        \"\"\"\t\n",
    "        End of: Getting bounding boxes\n",
    "        \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ==================     STEP6   ===================\n",
    "    Start of: Non-maximum suppression\n",
    "    \"\"\"\n",
    "\n",
    "    # Implementing non-maximum suppression of given bounding boxes\n",
    "    # With this technique we exclude some of bounding boxes if their\n",
    "    # corresponding confidences are low or there is another\n",
    "    # bounding box for this region with higher confidence\n",
    "\n",
    "    # It is needed to make sure that data type of the boxes is 'int'\n",
    "    # and data type of the confidences is 'float'\n",
    "    # https://github.com/opencv/opencv/issues/12789\n",
    "    results = cv2.dnn.NMSBoxes(boxes, confidences,\n",
    "                               probability_minimum, threshold)\n",
    "    \n",
    "    \"\"\"\n",
    "    End of: Non-maximum suppression\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    ==================     STEP6   ===================\n",
    "    Start of: Drawing bounding boxes and labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Checking if there is at least one detected object after non-maximum suppression\n",
    "    if len(results) > 0:\n",
    "        # Going through indexes of results\n",
    "        for i in results.flatten():\n",
    "            # Getting current bounding box coordinates, its width and height\n",
    "\n",
    "            x_min, y_min, box_width, box_height = boxes[i]\n",
    "\n",
    "            # Preparing colour for current bounding box and converting from numpy array to list\n",
    "            colour_box_current = colours[current_labels[i]].tolist()\n",
    "\n",
    "\n",
    "            label = str(labels[current_labels[i]])\n",
    "\n",
    "            # Drawing bounding box on the original current frame\n",
    "            if label in ['car', 'truck', 'bus', 'person']:\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_min + box_width, y_min + box_height), colour_box_current, 2)\n",
    "\n",
    "\n",
    "            #Calculating the pixel position of the center of the bounding box\n",
    "            center = (x_min + box_width//2, y_min + box_height//2)\n",
    "\n",
    "            frame_height = frame.shape[0]\n",
    "            frame_width = frame.shape[1]\n",
    "\n",
    "            #If the object in question is a vehicle\n",
    "            if(label in ['car', 'truck', 'bus']):\n",
    "                \n",
    "                text_box_current = '{}: {:.4f}'.format(label, confidences[i])\n",
    "\n",
    "                #Check if car crossed line or not by checking closest center in the old frame\n",
    "                \n",
    "                if(is_above_line_2D((0,int(y_threshold_1*frame_height)), (frame_width,int(y_threshold_2*frame_height)),center)):\n",
    "                    dists = []\n",
    "                    if(len(prev_results) > 0):\n",
    "                        for j in prev_results.flatten():\n",
    "                            if(label == labels[int(prev_labels[j])]):\n",
    "                                prev_x_min, prev_y_min, prev_box_width, prev_box_height = prev_boxes[j]\n",
    "                                prev_center = (prev_x_min + prev_box_width//2, prev_y_min + prev_box_height//2)\n",
    "                                dists.append([prev_center[0],prev_center[1],euclid_2D(center,prev_center)])\n",
    "                        if(len(dists) > 0):\n",
    "                            dists = np.array(dists)\n",
    "                            dists = dists[dists[:, 2].argsort()] \n",
    "                            if(not is_above_line_2D((0,int(y_threshold_1*frame_height)), (frame_width,int(y_threshold_2*frame_height)),(dists[0,0],dists[0,1]))):\n",
    "                                total_cars_count += 1\n",
    "                                if(dists[0,0] < parking_x_threshold * frame_width or dists[0,0] > (1-parking_x_threshold) * frame_width):\n",
    "                                    parked_cars_count += 1\n",
    "\n",
    "\n",
    "            #If the object in question is a pedestrian/person\n",
    "            elif(label == 'person'):\n",
    "\n",
    "                text_box_current = '{}: {:.4f}'.format(label, confidences[i])\n",
    "\n",
    "                #Check if car crossed line or not by checking closest center in the old frame\n",
    "                if(is_above_line_2D((0,int(pedestrian_y_threshold_1*frame_width)), (frame_width,int(pedestrian_y_threshold_2*frame.shape[0])),center)):\n",
    "                    dists = []\n",
    "                    if(len(prev_results) > 0):\n",
    "                        for j in prev_results.flatten():\n",
    "                            if(label == labels[int(prev_labels[j])]):\n",
    "                                prev_x_min, prev_y_min, prev_box_width, prev_box_height = prev_boxes[j]\n",
    "                                prev_center = (prev_x_min + prev_box_width//2, prev_y_min + prev_box_height//2)\n",
    "                                dists.append([prev_center[0],prev_center[1],euclid_2D(center,prev_center)])\n",
    "\n",
    "                        if(len(dists) > 0):\n",
    "                            dists = np.array(dists)\n",
    "                            dists = dists[dists[:, 2].argsort()] \n",
    "                            if(not is_above_line_2D((0,int(pedestrian_y_threshold_1*frame_width)), (frame_width,int(pedestrian_y_threshold_2*frame_width)),(dists[0,0],dists[0,1]))):\n",
    "                                total_pedestrian_count += 1\n",
    "            \n",
    "\n",
    "    passed_car_count_str = '{}: {:d}'.format(\"Total Passed Cars\",\n",
    "                                            total_cars_count)\n",
    "    passed_parked_car_count_str = '{}: {:d}'.format(\"Passed Parked Cars\",\n",
    "                                            parked_cars_count)\n",
    "    passed_moving_car_count_str = '{}: {:d}'.format(\"Passed Moving Cars\",\n",
    "                                total_cars_count - parked_cars_count)\n",
    "    passed_pedestrian_count_str = '{}: {:d}'.format(\"Passed Pedestrians\",\n",
    "                                            total_pedestrian_count)\n",
    "    \n",
    "    draw_label(frame, passed_car_count_str, (10, 20), (0,255,0))\n",
    "    draw_label(frame, passed_parked_car_count_str, (10, 40), (0,255,0))\n",
    "    draw_label(frame, passed_moving_car_count_str, (10, 60), (0,255,0))\n",
    "    draw_label(frame, passed_pedestrian_count_str, (10, 80), (0,255,0))\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Drawing bounding boxes and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    ==================     STEP7   ===================\n",
    "    Start of: Writing processed frame into the file\n",
    "    \"\"\"\n",
    "\n",
    "    # Initializing writer\n",
    "    # we do it only once from the very beginning when we get spatial dimensions of the frames\n",
    "    if writer is None:\n",
    "        # Constructing code of the codec to be used in the function VideoWriter\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "        # Writing current processed frame into the video file\n",
    "        writer = cv2.VideoWriter('result.mp4', fourcc, 30,\n",
    "                                 (frame.shape[1], frame.shape[0]), True)\n",
    "    \n",
    "    # Write processed current frame to the file\n",
    "    writer.write(frame)\n",
    "    \n",
    "    prev_boxes = boxes\n",
    "    prev_results = results\n",
    "    prev_labels = current_labels\n",
    "\n",
    "\"\"\"\n",
    "End of: Writing processed frame into the file\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "End of: Writing processed frame into the file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Printing final results\n",
    "print()\n",
    "print('Total number of frames', f)\n",
    "print('Total amount of time {:.5f} seconds'.format(t))\n",
    "\n",
    "\n",
    "# Releasing video reader and writer\n",
    "video.release()\n",
    "writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
